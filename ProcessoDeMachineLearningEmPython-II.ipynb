{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "                ####### MACHINE LEARNING EM PYTHON - REGRESSAO (ALGORTIMOS E METRICAS) #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'0.21.2'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import sklearn as sl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINIÇÃO DO PROBLEMA DE NEGÓCIO - Vamos criar um modelo preditivo que seja capaz de prever o preço de casas com base em uma série de variáveis (caracteristicas) sobre diversas casas em um bairro do Boston, codade dos EUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AVALIANDO A PERFORMANCE - As métricas que nos escolhemos para avaliar a performance do modelo vão influenciar a forma como a performance é medida e comparada com modelos criados com outros algortimos ####\n",
    "\n",
    "# MÉTRICAS PARA ALGORTIMOS DE REGRESSÃO #\n",
    "\n",
    "# . Mean Squared Error (MSE)\n",
    "# . Root Mean Squared Error (RMSE)\n",
    "# . Mean Absolute Error (MAE)\n",
    "# . R Squared (R²)\n",
    "# . Adjusted R Squared (R²)\n",
    "# . Mean Square Percentage Error (MSPE)\n",
    "# . Mean Absolute Percentage Error (MAPE)\n",
    "# . Root Mean Squared Logarithmic Error (RMSLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MSE (MEAN SQUARED ERROR) -> É talvez a metrica mais simples e comum para a avaliação de regressão, mas tambem provavelmente a menos util. O MSE basicamente mede o erro quadrado médio de nossas previsões. Para cada ponto, calcula a diferença quadrada entre as previsões e o valor real da variável alvo e, em seguida, calcula a média desses valores.\"Arquivos do Cap\"\n",
    "\n",
    "# Quanto maior esse valor, pior é o modelo. Esse valore nunca será negativo, ja que estamos elevando ao quadrado os erros individuais de previsão, mas seria zero para um modelo perfeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n0   0.00632  18.0   2.31     0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n1   0.02731   0.0   7.07     0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n2   0.02729   0.0   7.07     0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n3   0.03237   0.0   2.18     0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n4   0.06905   0.0   2.18     0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n5   0.02985   0.0   2.18     0  0.458  ...  222.0     18.7  394.12   5.21  28.7\n6   0.08829  12.5   7.87     0  0.524  ...  311.0     15.2  395.60  12.43  22.9\n7   0.14455  12.5   7.87     0  0.524  ...  311.0     15.2  396.90  19.15  27.1\n8   0.21124  12.5   7.87     0  0.524  ...  311.0     15.2  386.63  29.93  16.5\n9   0.17004  12.5   7.87     0  0.524  ...  311.0     15.2  386.71  17.10  18.9\n10  0.22489  12.5   7.87     0  0.524  ...  311.0     15.2  392.52  20.45  15.0\n11  0.11747  12.5   7.87     0  0.524  ...  311.0     15.2  396.90  13.27  18.9\n12  0.09378  12.5   7.87     0  0.524  ...  311.0     15.2  390.50  15.71  21.7\n13  0.62976   0.0   8.14     0  0.538  ...  307.0     21.0  396.90   8.26  20.4\n14  0.63796   0.0   8.14     0  0.538  ...  307.0     21.0  380.02  10.26  18.2\n15  0.62739   0.0   8.14     0  0.538  ...  307.0     21.0  395.62   8.47  19.9\n16  1.05393   0.0   8.14     0  0.538  ...  307.0     21.0  386.85   6.58  23.1\n17  0.78420   0.0   8.14     0  0.538  ...  307.0     21.0  386.75  14.67  17.5\n18  0.80271   0.0   8.14     0  0.538  ...  307.0     21.0  288.99  11.69  20.2\n19  0.72580   0.0   8.14     0  0.538  ...  307.0     21.0  390.95  11.28  18.2\n\n[20 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.02985</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.430</td>\n      <td>58.7</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.12</td>\n      <td>5.21</td>\n      <td>28.7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.08829</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>6.012</td>\n      <td>66.6</td>\n      <td>5.5605</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>395.60</td>\n      <td>12.43</td>\n      <td>22.9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.14455</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>6.172</td>\n      <td>96.1</td>\n      <td>5.9505</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>396.90</td>\n      <td>19.15</td>\n      <td>27.1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.21124</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>5.631</td>\n      <td>100.0</td>\n      <td>6.0821</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>386.63</td>\n      <td>29.93</td>\n      <td>16.5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.17004</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>6.004</td>\n      <td>85.9</td>\n      <td>6.5921</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>386.71</td>\n      <td>17.10</td>\n      <td>18.9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.22489</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>6.377</td>\n      <td>94.3</td>\n      <td>6.3467</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>392.52</td>\n      <td>20.45</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.11747</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>6.009</td>\n      <td>82.9</td>\n      <td>6.2267</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>396.90</td>\n      <td>13.27</td>\n      <td>18.9</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.09378</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0</td>\n      <td>0.524</td>\n      <td>5.889</td>\n      <td>39.0</td>\n      <td>5.4509</td>\n      <td>5</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>390.50</td>\n      <td>15.71</td>\n      <td>21.7</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.62976</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.949</td>\n      <td>61.8</td>\n      <td>4.7075</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>8.26</td>\n      <td>20.4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.63796</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.096</td>\n      <td>84.5</td>\n      <td>4.4619</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>380.02</td>\n      <td>10.26</td>\n      <td>18.2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.62739</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.834</td>\n      <td>56.5</td>\n      <td>4.4986</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>395.62</td>\n      <td>8.47</td>\n      <td>19.9</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.05393</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.935</td>\n      <td>29.3</td>\n      <td>4.4986</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>386.85</td>\n      <td>6.58</td>\n      <td>23.1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.78420</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.990</td>\n      <td>81.7</td>\n      <td>4.2579</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>386.75</td>\n      <td>14.67</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.80271</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.456</td>\n      <td>36.6</td>\n      <td>3.7965</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>288.99</td>\n      <td>11.69</td>\n      <td>20.2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.72580</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>5.727</td>\n      <td>69.5</td>\n      <td>3.7965</td>\n      <td>4</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>390.95</td>\n      <td>11.28</td>\n      <td>18.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# MSE - Mean Squared Error\n",
    "# Similar ao MAE, fornece a magnitude do erro do modelo.\n",
    "# Quanto maior, poir é o modelo.\n",
    "# Ao extrairmos a raiz quadrada do MSE convertemos as unidades de volta ao original,\n",
    "# o que pode ser util para descrição e apresenteção. Isso é chamado RMSE (Root Mean Squared Error)\n",
    "\n",
    "# Import dos modulos\n",
    "from pandas import read_csv\n",
    "\n",
    "# Carrgando o dataset\n",
    "arquivo = \"boston-houses.csv\"\n",
    "colunas = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "dados.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Valor do MSE: 28.53%\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Separando o array em dados de input e output\n",
    "array = dados.values\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os parametro do split\n",
    "test_size = 0.33\n",
    "seed = 5\n",
    "\n",
    "# Dividindo em dados de treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "linearModel = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "linearModel.fit(x_treino, y_treino)\n",
    "previsoes = linearModel.predict(x_teste)\n",
    "\n",
    "# Medindo a performance do modelo \n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Print das metricas\n",
    "print(\"Valor do MSE: %.2f%%\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Valor do MAE: 3.46%\n"
    }
   ],
   "source": [
    "# MAE\n",
    "# Mean Absolute Error\n",
    "# É a soma da diferença absoluta entre previsões e valores reais.\n",
    "# Fornece uma ideia de quão erradas estão nossas previsoes.\n",
    "# Valor igual a 0 indica que não há erro a previsão perfeita\n",
    "\n",
    "# Import dos modulos\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os valores para o split\n",
    "test_size = 0.33\n",
    "seed = 5\n",
    "\n",
    "# Dividindo em dados de treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "linearModel = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "linearModel.fit(x_treino, y_treino)\n",
    "previsoes = linearModel.predict(x_teste)\n",
    "\n",
    "# Calculando o MAE\n",
    "MAE = mean_absolute_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando os resultados\n",
    "print(\"Valor do MAE: %.2f%%\" % MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "R² Score: 0.70%\n"
    }
   ],
   "source": [
    "# R^2 -> Coeficiente e Determinação\n",
    "# Essa métrica fornece uma indicação do nível de precisão das previsões em relação aos valores observados\n",
    "# Também chamado de coeficiente de determinação\n",
    "# Valores entre 0 e 1, sendo 0 o valor ideal\n",
    "\n",
    "# Import do modulo\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando as variaveis input e output\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os parametros de Split\n",
    "test_size = 0.33\n",
    "seed= 5\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "linearModel = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "linearModel.fit(x_treino, y_treino)\n",
    "previsoes = linearModel.predict(x_teste)\n",
    "\n",
    "# Calculando  o R^2\n",
    "r2 = r2_score(y_teste, previsoes)\n",
    "\n",
    "# Visualizando o resultado\n",
    "print(\"R² Score: %.2f%%\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALGORITMOS DE REGRESSÃO ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSÃO LINEAR -> Assume que os dados estão em Distribuição Normal e tambem assume que as variáveis são relevantes para a construção do modelo e que não sejam colineares, ou seja, variáveis com alta correlação (cabe aos Cientistas de Dados, entregar ao algoritmo as variáveis realmente relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 28.53%\n"
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "linearModel = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "linearModel.fit(x_treino, y_treino)\n",
    "previsoes = linearModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RIDGE REGRESSION -> Extensão para a regressão linear onde a loss function é modificada para minimizar a complexidade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 29.29%\n"
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "ridgeModel = Ridge()\n",
    "\n",
    "# Treinando o modelo\n",
    "ridgeModel.fit(x_treino, y_treino)\n",
    "previsoes = ridgeModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LASSO REGRESSION (Least Absolute Shrinkeage and Selection Operator) -> É uma modificação da regressao linear e assim como a Ridge Regression, a loss function é modificada para minimizar a complexidade do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 33.39%\n"
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "lassoModel = Lasso()\n",
    "\n",
    "# Treinando o modelo\n",
    "lassoModel.fit(x_treino, y_treino)\n",
    "previsoes = lassoModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 33.27%\n"
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "elasticModel = ElasticNet()\n",
    "\n",
    "# Treinando o modelo\n",
    "elasticModel.fit(x_treino, y_treino)\n",
    "previsoes = elasticModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 47.71%\n"
    }
   ],
   "source": [
    "#### KNN #####\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "knnModel = KNeighborsRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "knnModel.fit(x_treino, y_treino)\n",
    "previsoes = knnModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 34.45%\n"
    }
   ],
   "source": [
    "#### CART #####\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "dTreeModel = DecisionTreeRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "dTreeModel.fit(x_treino, y_treino)\n",
    "previsoes = dTreeModel.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 93.22%\n"
    }
   ],
   "source": [
    "#### SVM #####\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criaçao do modelo\n",
    "svm_Model = SVR()\n",
    "\n",
    "# Treinando o modelo\n",
    "svm_Model.fit(x_treino, y_treino)\n",
    "previsoes = svm_Model.predict(x_teste)\n",
    "\n",
    "# Verificar a Precisão do modelo\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "\n",
    "# Visualizando a precisão do modelo\n",
    "print(\"MSE: %.2f%%\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OTIMIZAÇÃO DO MODELO -> AJUSTE DOS HIPERPARÂMETROS -> Todos os algoritmos de Machine Learning são parametrizados, o que significa que nos podemos ajustar a performance do nosso modelo preditivo, atraves do tuning(ajuste fino) dos parâmetros. Nosso trabalho é encontrar a melhor combinação entre os parametros em cada algortimo de Machine Learning. Esse processo tambem é chamado de Otimização de Hyperparâmetro. O sckit-learn oferece dois métodos para otimização automatica dos parametros: Grid Search Parameter Tuning e Random Search Parameter Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Melhores Parametros do Modelo:  Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n      normalize=False, random_state=None, solver='auto', tol=0.001)\n"
    }
   ],
   "source": [
    "## GRID SEARCH PARAMETER TUNING -> Este metodo realiza metodicamente combinações entre todos os parametros do algoritmo, criando uma grid. Vamos experimentar este metodo utilizando o algortim ode regressao ridge.\n",
    "\n",
    "# Import dos módulos\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os valores que serao testedos\n",
    "valores_alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0])\n",
    "valores_grid = dict(alpha = valores_alphas)\n",
    "\n",
    "# Criaçao do modelo\n",
    "ridgeModel = Ridge()\n",
    "\n",
    "# Criando o grid\n",
    "grid = GridSearchCV(estimator = ridgeModel, param_grid = valores_grid)\n",
    "grid.fit(x, y)\n",
    "\n",
    "# Visualizando os melhores parametros\n",
    "print(\"Melhores Parametros do Modelo: \", grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Melhores Parametros do Modelo:  Ridge(alpha=0.9779895119966027, copy_X=True, fit_intercept=True, max_iter=None,\n      normalize=False, random_state=None, solver='auto', tol=0.001)\n"
    }
   ],
   "source": [
    "## GRID SEARCH PARAMETER TUNING -> Este metodo gera amostras a dos parametros dos algortimos a partir de uma distribuição randomica uniforme para um numero fixo de iterações. Um modelo é construido e testado para cada combinação de parametros. Neste exemplo veremos que o valor muito proximo de 1 para o parametro alpha é o que vai apresentar os melhores resultados\n",
    "\n",
    "# Import dos módulos\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os valores que serao testedos\n",
    "valores_grid = {\"alpha\": uniform()}\n",
    "seed = 7\n",
    "\n",
    "# Criaçao do modelo\n",
    "ridgeModel = Ridge()\n",
    "iterations = 100\n",
    "\n",
    "# Criando o grid\n",
    "rsearch = RandomizedSearchCV (\n",
    "    estimator = ridgeModel,\n",
    "    param_distributions = valores_grid,    \n",
    "    n_iter = iterations,\n",
    "    random_state = seed\n",
    ")   \n",
    "\n",
    "rsearch.fit(x, y)\n",
    "\n",
    "# Visualizando os melhores parametros\n",
    "print(\"Melhores Parametros do Modelo: \", rsearch.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Modelo Salvo!\nModelo Carregado!\nMSE:  24.8581631211166\n"
    }
   ],
   "source": [
    "## SALVANDO O RESULTADO DO TRABALHO ##\n",
    "\n",
    "# Import dos módulos\n",
    "import pickle\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Carregando os dados\n",
    "array = dados.values\n",
    "\n",
    "# Separando os dados\n",
    "x = array[:,0:13]\n",
    "y = array[:,13]\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "test_size = 0.35\n",
    "seed = 7\n",
    "\n",
    "# Split dos dados\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = test_size, random_state = seed)\n",
    "\n",
    "# Criaçao do modelo\n",
    "ridgeModel = Ridge()\n",
    "\n",
    "# Treinando o modelo\n",
    "ridgeModel.fit(x_treino, y_treino)\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = \"modelo_regressor_final.sav\"\n",
    "pickle.dump(ridgeModel, open(arquivo, \"wb\"))\n",
    "print(\"Modelo Salvo!\")\n",
    "\n",
    "# Carregando o arquivo\n",
    "modelo_regressor_final = pickle.load(open(arquivo, \"rb\"))\n",
    "print(\"Modelo Carregado!\")\n",
    "\n",
    "# Print dos resutados\n",
    "# Fazendo previsoes\n",
    "previsoes = modelo_regressor_final.predict(x_teste)\n",
    "\n",
    "# Resutado\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "print(\"MSE:\", mse)"
   ]
  }
 ]
}